<a href="https://chat.vercel.ai/">
  <img alt="Next.js 14 and App Router-ready AI chatbot." src="app/(chat)/opengraph-image.png">
  <h1 align="center">Chat SDK</h1>
</a>

<p align="center">
    Chat SDK is a free, open-source template built with Next.js and the AI SDK that helps you quickly build powerful chatbot applications.
</p>

<p align="center">
  <a href="https://chat-sdk.dev"><strong>Read Docs</strong></a> ·
  <a href="#features"><strong>Features</strong></a> ·
  <a href="#model-providers"><strong>Model Providers</strong></a> ·
  <a href="#deploy-your-own"><strong>Deploy Your Own</strong></a> ·
  <a href="#running-locally"><strong>Running locally</strong></a>
</p>
<br/>

## Features

- [Next.js](https://nextjs.org) App Router
  - Advanced routing for seamless navigation and performance
  - React Server Components (RSCs) and Server Actions for server-side rendering and increased performance
- [AI SDK](https://sdk.vercel.ai/docs)
  - Unified API for generating text, structured objects, and tool calls with LLMs
  - Hooks for building dynamic chat and generative user interfaces
  - Supports xAI (default), OpenAI, Fireworks, and other model providers
- [shadcn/ui](https://ui.shadcn.com)
  - Styling with [Tailwind CSS](https://tailwindcss.com)
  - Component primitives from [Radix UI](https://radix-ui.com) for accessibility and flexibility
- Data Persistence
  - [Ducky.ai](https://ducky.ai/) for knowledge base storage, chunking, embedding, and retrieval (no longer using Vercel Blob)
- [Auth.js](https://authjs.dev)
  - Simple and secure authentication

## Model Providers

This template ships with [xAI](https://x.ai) `grok-2-1212` as the default chat model. However, with the [AI SDK](https://sdk.vercel.ai/docs), you can switch LLM providers to [OpenAI](https://openai.com), [Anthropic](https://anthropic.com), [Cohere](https://cohere.com/), and [many more](https://sdk.vercel.ai/providers/ai-sdk-providers) with just a few lines of code.

## Retrieval-Augmented Generation (RAG) System

### ⚡️ Now Powered by Ducky.ai

This project uses [Ducky.ai](https://ducky.ai/) for all knowledge base document storage, chunking, embedding, indexing, and retrieval. Vercel Blob is no longer used for knowledge storage.

- **Knowledge Base Upload**: Documents are uploaded directly to Ducky.ai, which handles chunking, embedding, and indexing.
- **Retrieval**: When the chatbot receives a query, it retrieves relevant context from Ducky.ai using its API.
- **Prompt Assembly**: Retrieved context is injected into the LLM prompt for accurate, context-aware responses.

#### Key Changes:
- All legacy chunking, embedding, and retrieval code using Supabase/pgvector or Vercel Blob is now disabled.
- The `/api/chat` endpoint calls Ducky.ai for retrieval.
- File uploads still use Vercel Blob, but chunking/embedding is handled by Ducky.ai.

#### Environment Variable
- Add your Ducky.ai API key to `.env` as:
  ```env
  DUCKY_API_KEY=your-ducky-api-key-here
  ```
- This is required for chat retrieval to function.

#### Example Retrieval Call
```js
const response = await fetch('https://api.ducky.ai/v1/documents/retrieve', {
  method: 'POST',
  headers: {
    'content-type': 'application/json',
    'x-api-key': process.env.DUCKY_API_KEY,
  },
  body: JSON.stringify({
    index_name: 'knowledge',
    query: userQuestion,
    top_k: 5,
    alpha: 1,
    rerank: false,
  }),
});
const data = await response.json();
const contextChunks = data.chunks.map(chunk => chunk.content).join('\n');
```

## Deploy Your Own

You can deploy your own version of the Next.js AI Chatbot to Vercel with one click:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fai-chatbot&env=AUTH_SECRET&envDescription=Generate%20a%20random%20secret%20to%20use%20for%20authentication&envLink=https%3A%2F%2Fgenerate-secret.vercel.app%2F32&project-name=my-awesome-chatbot&repository-name=my-awesome-chatbot&demo-title=AI%20Chatbot&demo-description=An%20Open-Source%20AI%20Chatbot%20Template%20Built%20With%20Next.js%20and%20the%20AI%20SDK%20by%20Vercel&demo-url=https%3A%2F%2Fchat.vercel.ai&products=%5B%7B%22type%22%3A%22integration%22%2C%22protocol%22%3A%22ai%22%2C%22productSlug%22%3A%22grok%22%2C%22integrationSlug%22%3A%22xai%22%7D%2C%7B%22type%22%3A%22integration%22%2C%22protocol%22%3A%22storage%22%2C%22productSlug%22%3A%22neon%22%2C%22integrationSlug%22%3A%22neon%22%7D%2C%7B%22type%22%3A%22blob%22%7D%5D)

## Running locally

You will need to use the environment variables [defined in `.env.example`](.env.example) to run Next.js AI Chatbot. It's recommended you use [Vercel Environment Variables](https://vercel.com/docs/projects/environment-variables) for this, but a `.env` file is all that is necessary.

> Note: You should not commit your `.env` file or it will expose secrets that will allow others to control access to your various AI and authentication provider accounts.

1. Install Vercel CLI: `npm i -g vercel`
2. Link local instance with Vercel and GitHub accounts (creates `.vercel` directory): `vercel link`
3. Download your environment variables: `vercel env pull`

```bash
pnpm install
pnpm dev
```

Your app template should now be running on [localhost:3000](http://localhost:3000).
